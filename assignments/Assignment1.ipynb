{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallpaz/3dsystems21/blob/main/assignments/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK14t1ac77Dx"
      },
      "source": [
        "### **Part 1: Google Colab Setup**\n",
        "\n",
        "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
        "\n",
        "1. Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y12MWoY79kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4d203c-cfb4-4dea-9e87-42cce7495cf8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRJEnSUWANe3"
      },
      "source": [
        "2. You can use command line instructions like `ls` and `cd` to find the folder that this notebook is stored. Move to this folder by changing the code below to access your folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSsoyliYB-lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0c5f0c-2bb1-4b7b-9e4e-c5304c22fe10"
      },
      "source": [
        "%ls \"/content/drive/MyDrive/s3d21\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mr2n2\u001b[0m/  \u001b[01;34mSNCorev2\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUeSQwrLGYXu"
      },
      "source": [
        "3. If you're using python scripts together with your implementation we recommend using the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit .py source files, and re-import them into the notebook for a seamless editing and debugging experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fA76IUEGE4y"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdzT8e1jG-09"
      },
      "source": [
        "### **Part 2: PyTorch Tensors**\n",
        "\n",
        "As instructed in class we'll be using PyTorch in all throught the semester, for more information check the assignment instructions page and the references provided.\n",
        "\n",
        "1. Start by importing and checking PyTorch version. In case you're running locally, you must be sure to have [installed](https://pytorch.org/get-started/locally/) the latest version in a proper environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtUVDvM_GVHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab3a1df-ba57-438f-e530-ced00f5b597f"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmGl1VmTJko1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7af2cd-11c2-47d3-b9a3-260b7d772fa8"
      },
      "source": [
        "# Example\n",
        "# 2x2 tensor built from a regular array\n",
        "T = torch.tensor( [ [1,2], [3, 4] ] )\n",
        "print(T)\n",
        "\n",
        "T_row = T[0,:]\n",
        "T_cln = T[:,0]\n",
        "T_e =   T[0,0].item()\n",
        "print(T[0,0], T_e)\n",
        " \n",
        "print(T.dtype)\n",
        "print(T.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor(1) 1\n",
            "torch.int64\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqDGqAqvKdZB"
      },
      "source": [
        "2. Run the example above, or a similar one, but experiment using the functions: `torch.Tensor`, `torch.as_tensor` and `torch.empty` when creating tensors. You should also check `torch.set_default_dtype` and experiment with it. See [doc](https://pytorch.org/docs/stable/torch.html#)\n",
        "3. You must check for differences in how PyTorch handles memory and data type.\n",
        "4. Write on markdown or as a comment a brief comment on what is the difference between using those or the standard `torch.tensor`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SswoNX6XJJpE"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 2-4.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNVFnm9zOg3G"
      },
      "source": [
        "5. Write a function that receives a 2D tensor as input and returns a tensor of same size that is \n",
        "- equal to the input on the first row\n",
        "- 2 times the input's second row on the second row\n",
        "- 3 times the input's third row on the third row\n",
        "- etc..\n",
        "\n",
        "For instance:\n",
        "```\n",
        ">>> t = torch.full((4, 8), 2.0)\n",
        ">>> t\n",
        "tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
        "[2., 2., 2., 2., 2., 2., 2., 2.],\n",
        "[2., 2., 2., 2., 2., 2., 2., 2.],\n",
        "[2., 2., 2., 2., 2., 2., 2., 2.]])\n",
        ">>> mul_row(t)\n",
        "tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
        "[4., 4., 4., 4., 4., 4., 4., 4.],\n",
        "[6., 6., 6., 6., 6., 6., 6., 6.],\n",
        "[8., 8., 8., 8., 8., 8., 8., 8.]])\n",
        "```\n",
        "\n",
        "6. You must use tensor operations to do so, which means no loops.\n",
        "  **Hint**: Use broadcasting and `torch.arange`, `torch.view`, and `torch.mul`.\n",
        "\n",
        "7. *Extra*: You can also implement a simpler version using loops and simple indexing, and then compare the two functions using `times` for large tensors (ex: `torch.ones(1000,500)`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdEwTy8NOdj1"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 5-7.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oun2IeKbTSw4"
      },
      "source": [
        "For the following parts you'll practice how to train and evaluate a neural network trained on MNIST.\n",
        "\n",
        "### **Part 3: Handling Data**\n",
        "\n",
        "**MNIST**, is a famous dataset containing 70,000 grayscale hand-written digits (0-9) and their associated values. PyTorch `torchvision.dataset` gives us access to a few datasets including this one. The dataset is divided as 60,000 training images and 10,000 for the test set.\n",
        "\n",
        "Using MNIST you should construct a neural network classifier that can predict the digits in an image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tesC0ALEIZd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "d56fbe95-b1ad-4949-c07e-504c6e5c0cd4"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "#example\n",
        "mnist_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.1307,), (0.3081,)) ])\n",
        "mnist_data = MNIST(os.getcwd(), download=True, transform=mnist_transform)\n",
        "\n",
        "image, label = mnist_data.__getitem__(2020)\n",
        "plt.imshow(  image.view(28,28).numpy(), cmap = 'gray_r' )\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAGBElEQVR4nO3dTYjNexzH8TOakOfSLJQNKZStlAW2VlNKHjYWFhYetp5qIlZ2FjaSnZQGR6yIEmVlJU8ry6lxFhOKLJy7uovbnf/35Mwc8zn3vl7L+fQbf+ntX36dMdLtdltAnkUL/QDA7MQJocQJocQJocQJoUZ77P4pFwZvZLYvenNCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCqF6f5yTMoUOHyv39+/fl/vTp03Jfu3btbz8Tg+HNCaHECaHECaHECaHECaHECaFGevxHRn405h/29evXct+4cWO5dzqdcr9x40a5Hz16tNwZCD8aE4aJOCGUOCGUOCGUOCGUOCGUOCGUj4yFefHiRbn3usccGxsr9yNHjvz2M7EwvDkhlDghlDghlDghlDghlDghlDghlHvOMO12e07ne/3ozNFRf+TDwpsTQokTQokTQokTQokTQokTQokTQrn0CvP48eM5nd++ffs8PQkLzZsTQokTQokTQokTQokTQokTQrlKWQCvX79u3Kanp8uz27ZtK/fx8fG+nok83pwQSpwQSpwQSpwQSpwQSpwQSpwQyj3nAPz69avcr1y50rh9//69PHvq1KlyX7lyZbkzPLw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zgGYmpoq9zt37vT9vd1j/n94c0IocUIocUIocUIocUIocUIocUIo95wD8ObNm77Prlq1qtz37t3b9/dmuHhzQihxQihxQihxQihxQihxQihxQij3nAMwMzPT99mDBw+W++rVq/v+3q1Wq/Xp06dy73Q6jdv169fLs71+Xu+OHTvK/cCBA43bXH/fw8ibE0KJE0KJE0KJE0KJE0KJE0K5ShmAd+/e9X323Llzc/q1L1y4UO7Xrl0r9+oqZa5u3rxZ7pOTk41bu90uzy5btqyvZ0rmzQmhxAmhxAmhxAmhxAmhxAmhxAmh3HMOwMuXL/s+2+ue8eTJk+X+8OHDcl+6dGm5b926tXE7duxYeXbRovrv+l7P9uTJk8bt7Nmz5dmrV6+W+zDy5oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQI91ut9rLkdnt2bOn3J8/f964rVu3rjw7NTVV7ps3by73iYmJcj98+HC5z8WrV6/KfefOnY3b2NhYeXZ6erqvZwoxMtsXvTkhlDghlDghlDghlDghlDghlDghlM9zDsDbt2/7PtvrHrPX5zEvXbpU7vv37//tZ5ovve5w+SdvTgglTgglTgglTgglTgglTgglTgjlnnPIXLx4sdwX8h6zl0ePHvV9dsOGDfP4JMPBmxNCiRNCiRNCiRNCiRNCiRNCuUoZMmvWrCn3b9++lfuKFSvm83H+4cePH+V+//79cl+yZEnjtm/fvr6eaZh5c0IocUIocUIocUIocUIocUIocUIo95wDsH79+nLvdDp9f+/Tp0+X+8+fP8v9xIkTff/aHz9+LPczZ86U+7Nnz8r9+PHjjVuv3/d/kTcnhBInhBInhBInhBInhBInhBInhBrpdrvVXo7MbnJystyrH19Zfaax1Wq17t27V+67d+8u98+fP5f73bt3G7fLly+XZ2dmZsp9fHy83G/dutW4LV++vDw75EZm+6I3J4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RyzzkAve4Sd+3a1bh9+PBhvh/njzl//ny5T0xMlPvixYvn83GGiXtOGCbihFDihFDihFDihFDihFCuUhbAly9fGrdeHwlrt9vl/uDBg76e6W9btmxp3G7fvl2e3bRpU7kP8r8fHHKuUmCYiBNCiRNCiRNCiRNCiRNCiRNCueeEheeeE4aJOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCHUaI995I88BfAv3pwQSpwQSpwQSpwQSpwQSpwQ6i9VMeCLqoVw0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSuu3m6KSOKe"
      },
      "source": [
        "1. Now you must create a train-test-val split. \n",
        "  * First check [here](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) to know how to get a train-test split. Then use `random_split` to break your train set in a ratio [55000, 5000]. \n",
        "  * Create their respective loaders using `DataLoader`.\n",
        "  * Create a function that receives a batch of images and can plot them in a organized manner. Check [here](https://matplotlib.org/3.3.1/tutorials/index.html).\n",
        "  * Check the size of the datasets, as well as the shape of the images.\n",
        "  * Check how balanced each dataset split is: You can use `torch.bincount` feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_EVH8VWPZic"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 1.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKbGxgXYU5Js"
      },
      "source": [
        "2. Using `torch.nn` define a two layers feedforward neural network with a ReLU activation. The network must receive the image in its original shape, and reshape it in order to pass throught the linear layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ca24yNAU38R"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 2.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU3HoD82aZDL"
      },
      "source": [
        "3. Using the `CrossEntropyLoss` loss function you must set a SGD optimizer and train your network on the MNIST for at least 10 epochs. You should set a print statement or a progress bar to print your training loss.\n",
        "\n",
        "4. Test your model in your test dataset. Remember to use `torch.no_grad`.\n",
        "\n",
        "5. Change your learning rate and batch size one or two times to observe how the test performance varies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_zStvNLdm8c"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 3-5.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGto59MQfu69"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC7kfmiofuBH"
      },
      "source": [
        "6. Next, change the runtime of colab for running with the GPU and modify your code to run in the gpu.\n",
        "\n",
        "7. Add a validation step in your training loop, saving your validation loss throughout the training. After the training plot the curve of the progress of this validation loss.\n",
        "\n",
        "8. Add an accuracy measure in the validation loop. You might have to modify your model in order to get the logit values, then you can use `torch.argmax` to obtain the labels predicted, which you must them compare with the true labels. Plot the evolution of the accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrfqm-TPjeeC"
      },
      "source": [
        "##############################################################################\n",
        "# Code for 6-8.\n",
        "##############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWHKvxU9kGP6"
      },
      "source": [
        "9. **[EXTRA]** Plot the confusion matrix for your result model. I suggest using [Seaborn](https://seaborn.pydata.org/). And evaluate the performance of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X79SrFCsjgEn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}